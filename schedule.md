---
title: Program Schedule
layout: default
weight: 7
---

# {{ site.data.conference.short_name }} {{ site.data.conference.year }} Program Schedule 

**Schedule is tentative and is subject to changes!**

**All times are CEST.**
You can check current CEST time [here](https://time.is/CEST).


## Registration Desk

Registration desk is open on:
+ 17:00-20:00 on Mon, April 24th
+ 7:00-17:00 on Tue, April 25th and Wed, April 26th
+ 8:30-17:00 on Thu, April 27th

## Schedule for Day 1: Tue, April 25

<table>
<tr>   
<th> Time (<a href="https://time.is/CEST">CEST</a>)  </th>
<th> <b>Day 1: Tue, April 25</b>
</th>
</tr>

<tr>
<td>
08:45-09:00 
</td>
<td>
Opening remarks
</td>
</tr>

<tr>
<td>
09:00-10:00
</td>
<td>
<a href="{{ "/invited.html#arthur-gretton" | relative_url }}">Keynote Talk: Arthur Gretton (UCL Gatsby)</a>
</td>
</tr>

<tr>
<td>
10:00-10:30
</td>
<td>
Coffee break
</td>
</tr>

<tr>
<td>
10:30-11:30 
</td>
<td>
<details>
<summary> <b>Oral Session 1 | Optimal Transport, Information Theory</b>  </summary>
<ul>
<li> The Schr√∂dinger Bridge between Gaussian Measures has a Closed Form  
</li>  
<li> Rethinking Initialization of the Sinkhorn Algorithm   
</li>
<li> Using Sliced Mutual Information to Study Memorization and Generalization in Deep Neural Networks   
</li>
<li> Mode-Seeking Divergences: Theory and Applications to GANs
</li>
</ul>
</details>
</td>
</tr>

<tr>
<td>
11:30-12:30
</td>
<td>
Affinity Groups Panel
</td>
</tr>

<tr>
<td>
12:30-14:00
</td>
<td>
Lunch break	
</td>
</tr>

<tr>
<td>
14:00-15:00
</td>
<td>
<details>
<summary> <b>Oral Session 2 | Trustworthy ML and Statistics</b>  </summary>
<ul>
<li> Who Should Predict? Exact Algorithms For Learning to Defer to Humans   
</li>
<li> Generalized PTR: User-Friendly Recipes for Data-Adaptive Algorithms with Differential Privacy   
</li>
<li> Origins of Low-Dimensional Adversarial Perturbations   
</li>
<li> Data Banzhaf: A Robust Data Valuation Framework for Machine Learning
</li>
</ul>
</details>
</td>
</tr>

<tr>
<td>
15:00-15:30
</td>
<td>
Coffee break
</td>
</tr>

<tr>
<td>
15:30-16:30
</td>
<td>
<details>
<summary> <b>Oral Session 3 | Representations of Graphs</b>  </summary>
<ul>
<li> The Power of Recursion in Graph Neural Networks for Counting Substructures   
</li>
<li> Implicit Graphon Neural Representation   
</li>
<li> Implications of sparsity and high triangle density for graph representation learning   
</li>
<li> Fitting low-rank models on egocentrically sampled partial networks
</li>
</ul>
</details>
</td>
</tr>

<tr>
<td>
16:30-19:00
</td>
<td>
Poster session 1
</td>
</tr>

</table>



## Schedule for Day 2: Wed, April 26th

<table>
<tr>   
<th> Time (<a href="https://time.is/CEST">CEST</a>)  </th>
<th> <b>Day 2: Wed, April 26th</b>
</th>
</tr>

<tr>
<td>
08:00-09:00
</td>
<td>
Mentoring Event 1
</td>
</tr>

<tr>
<td>
09:00-10:00
</td>
<td>
<a href="{{ "/invited.html#shakir-mohammed" | relative_url }}">Keynote Talk: Shakir Mohamed (Deepmind)</a>
</td>
</tr>

<tr>
<td>
10:00-10:30 
</td>
<td>
Coffee break  
</td>
</tr>

<tr>
<td>
10:30-11:30
</td>
<td>
<details>
<summary> <b>Oral Session 4 | Probabilistic Methods 1</b>  </summary>
<ul>
<li> Do Bayesian Neural Networks Need To Be Fully Stochastic?   
</li>
<li> Indeterminacy in Generative Models: Characterization and Strong Identifiability   
</li>
<li> Distance-to-Set Priors and Constrained Bayesian Inference   
</li>
<li> Particle algorithms for maximum likelihood training of latent variable models
</li>
</ul>
</details>
</td>
</tr>

<tr>
<td>
11:30-12:30
</td>
<td>
<details>
<summary> <b>Oral Session 5 | Probabilistic Methods 2</b>  </summary>
<ul>
<li> BaCaDI: Bayesian Causal Discovery with Unknown Interventions   
</li>
<li> Multilevel Bayesian Quadrature   
</li>
<li> Discovering Many Diverse Solutions with Bayesian Optimization   
</li>
<li> Inducing Point Allocation for Sparse Gaussian Processes in High-Throughput Bayesian Optimisation
</li>
</ul>
</details>
</td>
</tr>

<tr>
<td>
12:30-14:00 
</td>
<td>
Lunch break  
</td>
</tr>

<tr>
<td>
14:00-15:00
</td>
<td>
<a href="{{ "/awards.html" | relative_url }}">Test of Time Award: Andreas Damianou and Neil Lawrence</a>
<br>
<a href="http://proceedings.mlr.press/v31/damianou13a.pdf">Deep Gaussian Processes</a> (published at AISTATS 2013)
</td>
</tr>

<tr>
<td>
15:00-15:30 
</td>
<td>
Coffee break  
</td>
</tr>

<tr>
<td>
15:30-16:30
</td>
<td>
<details>
<summary> <b>Oral Session 6 | Statistical Methods 1</b>  </summary>
<ul>
<li> Huber-robust confidence sequences   
</li>
<li> Error Estimation for Random Fourier Features    
</li>
<li> A Tale of Sampling and Estimation in Discounted Reinforcement Learning   
</li>
<li> Safe Sequential Testing and Effect Estimation in Stratified Count Data
</li>

</ul>
</details>
</td>
</tr>

<tr>
<td>
16:30-19:00
</td>
<td>
Poster session 2
</td>
</tr>

</table>



## Schedule for Day 3: Thu, April 27th

<table>
<tr>   
<th> Time (<a href="https://time.is/CEST">CEST</a>)  </th>
<th> <b>Day 2: Wed, April 26th</b>
</th>
</tr>

<tr>
<td>
08:00-09:00
</td>
<td>
Mentoring Event 2
</td>
</tr>

<tr>
<td>
09:00-10:00
</td>
<td>
<a href="{{ "/invited.html#tamara-broderick" | relative_url }}">Keynote Talk: Tamara Broderick (MIT)</a>
</td>
</tr>

<tr>
<td>
10:00-10:30 
</td>
<td>
Coffee break  
</td>
</tr>

<tr>
<td>
10:30-11:30
</td>
<td>
<details>
<summary> <b>Oral Session 7 | Supervised Learning</b>  </summary>
<ul>
<li> Don't be fooled: label leakage in explanation methods and the importance of their quantitative evaluation   
</li>
<li> Fix-A-Step: Semi-supervised Learning From Uncurated Unlabeled Data   
</li>
<li> Blessing of Class Diversity in Pre-training   
</li>
<li> Federated Learning under Distributed Concept Drift
</li>
</ul>
</details>
</td>
</tr>

<tr>
<td>
11:30-12:30
</td>
<td>
<details>
<summary> <b>Oral Session 8 | Statistical Methods 2</b>  </summary>
<ul>
<li> Scalable Bicriteria Algorithms for Non-Monotone Submodular Cover   
</li>
<li> Noisy Low-rank Matrix Optimization: Geometry of Local Minima and Convergence Rate   
</li>
<li> An Efficient and Continuous Voronoi Density Estimator   
</li>
<li> Hedging against Complexity: Distributionally Robust Optimization with Parametric Approximation
</li>
</ul>
</details>
</td>
</tr>

<tr>
<td>
12:30-14:00
</td>
<td>
Lunch break  
</td>
</tr>

<tr>
<td>
14:00-16:30 
</td>
<td>
Poster session 3 
</td>
</tr>

</table>
